---
title: '[데이터 크롤링] 웹 크롤링 with Python'

categories:
  - Data Analysis
tags:
  - Data Analysis
  - Data Crawling

last_modified_at: 2021-03-12T08:06:00-05:00

classes: wide
---

이 글은 웹 크롤링에 관한 기록입니다.

## 1. 크롤링 개념

웹 크롤링(web crawling) 혹은 웹 스크래핑(web scraping)은 웹 페이지에 존재하는 내용들을 수집하는 것을 말합니다. 이에 사용되는 것을 웹 크롤러(web crawler)라고 합니다. 웹 크롤러는 웹 스파이더(web spider), 웹 로봇(web robot), 봇(bots) 등으로도 불립니다.

## 2. 크롤링 과정

웹 크롤링은 클라이언트가 웹 서버에 데이터를 요청(Request)하고, 웹 서버가 해당 요청에 대한 결과를 응답(Response)하면서 이루어집니다. 웹 크롤링 과정은 다음과 같습니다.

1. HTTP Request & HTTP Response
    - HTTP 요쳥 및 HTTP 응답 결과 확인
2. HTML Parsing
    - 응답 받은 객체를 HTML/JSON로 변환
3. Extract & Preprocessing Data
    - CSS Selector, XPath 등을 이용하여 HTML로부터 수집하고자 하는 데이터 추출 및 전처리
4. Save Data


### HTTP (HyperText Transfer Protocol)

HTTP는 ‘초본문 전송 규약’이라고 번역할 수 있는데, 
인터넷(world wide web) 상에서 데이터를 주고 받을 때 사용되며, 
주로 HTML을 주고 받습니다.

데이터를 주고 받는 당사자는 ‘클라이언트(Client)’와 ‘웹서버(Web Server)’입니다.

클라이언트가 웹서버에 데이터를 요청(Request)하고, 웹서버는 해당 요청에 대한
결과를 응답(Response)합니다.

클라이언트가 요청할 때 사용할 수 있는 방식(Method)에는 여러 가지가 있으며, 가장 많이 사용되는 것이 GET 방식과 POST 방식입니다.

## 3. 크롤링 종류

크롤링에는 크게 정적 웹 페이지를 크롤링 하는 정적 크롤링과 동적 웹 페이지를 크롤링 하는 동적 크롤링이 존재합니다.

### 정적 페이지 vs. 동적 페이지

|정적 웹 페이지|동적 웹 페이지|
|-----------|----------|
|웹 서버에 이미 저장된 html 문서를 클라이언트에게 전송하는 웹 페이지|요청 정보를 처리한 후에 제작된 html 문서를 클라이언트에게 전송하는 웹 페이지|
|사용자는 서버에 저장된 데이터가 변경되지 않는 한 고정된 웹페이지를 보게 됨|사용자는 상황, 시간, 요청 등에 따라 달라지는 웹페이지를 보게 됨|
|모든 사용자는 같은 결과의 웹 페이지를 서버에 요청하고 응답받음|같은 페이지라도 사용자마다 다른 결과의 웹페이지를 서버에 요청하고 받을 수 있음|

- 정적 웹 페이지
  - 웹 서버에 이미 저장된 html 문서를 클라이언트에게 전송하는 웹 페이지
  - 사용자는 서버에 저장된 데이터가 변경되지 않는 한 고정된 웹페이지를 보게 됨
  - 모든 사용자는 같은 결과의 웹 페이지를 서버에 요청하고 응답받음
- 동적 웹 페이지
  - 요청 정보를 처리한 후에 제작된 html 문서를 클라이언트에게 전송하는 웹 페이지
  - 사용자는 상황, 시간, 요청 등에 따라 달라지는 웹페이지를 보게 됨
  - 같은 페이지라도 사용자마다 다른 결과의 웹페이지를 서버에 요청하고 받을 수 있음

### 정적 크롤링

정적 웹 크롤링은 정적 웹 페이지를 크롤링 하기 위한 것입니다. 정적 웹 페이지는 웹 서버에 이미 저장된 html 문서를 클라이언트에게 전송하는 웹 페이지를 가리킵니다. 파이썬을 사용하여 정적 웹 크롤링을 할 경우 `requests`, `BeautifulSoup`이 필요합니다.

- `request` : 웹 사이트에 접속, 데이터를 받아오는 역할
- `BeautifulSoup` : 데이터를 HTML로 해석하는 역할

- request: 웹 사이트에 접속, 데이터를 받아오는 역할 / HTTP 요청을 담당하는 라이브러리
- BeautifulSoup: 데이터를 HTML로 해석하는 역할 / BeautifulSoup (bs4) 내에 속함 - HTML로부터 우리가 원하는 데이터를 추출할 수 있게 해줌

- BeautifulSoup Parser의 종류
  - `'html.parser'`: 적당히 빠르고 가벼움
  - `'lxml'`: 매우 빠르나 외부 C 라이브러리에 의존
  - `'xml'`: 매우 빠르고 xml 해석기 지원함 / 외부 C라이브러리에 의존
  - `'html5lib'`: 웹 브라우저 방식으로 페이지 해석, HTML5 생성 / 외부 파이썬 라이브러리 사용, 아주 느리고 파이썬 2 버전만 사용


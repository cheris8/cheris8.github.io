---
title: '[NLP] BERT'

categories:
  - Natural Language Processing
tags:
  - Text Preprocessing
  - Text Mining
  - Natural Language Processing
  - Deep Learning

last_modified_at: 2020-11-15T08:06:00-05:00

classes: wide
use_math: true
---

이 글은 원 논문인 [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)을 공부한 기록입니다.

## 0. Abstract




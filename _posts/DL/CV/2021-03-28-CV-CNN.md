---
title: '[딥러닝] CNN (Convolution Neural Networks) ; 합성곱 신경망'

categories:
  - Deep Learning
tags:
  - Deep Learning

last_modified_at: 2021-03-28T08:06:00-05:00

classes: wide
use_math: true
---

이 글은 CNN의 개념, 구조, 순전파, 역전파에 관한 기록입니다.

## CNN 개념

CNN은 이미지를 다루는 데에 활용되는 Deep Neural Network입니다. CNN의 목표는 정보의 손실 없이 이미지를 줄이는 것입니다. 이를 위해 CNN에서는 Convolution layer와 ReLU layer, Pooling layer를 통해 feature를 학습하고, Fully-Connected layer를 통해 이미지를 분류합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-overview.jpeg)

즉 CNN은 크게 Convolution layer, Pooling layer, Full-Connected layer 세가지 종류의 layer로 구성됩니다.

> `((CONV + RELU) * m => POOL) * n => (FC + RELU) * k`  
> `m` = 1~5, `n` = 큰 수, `k` = 0~2

## CNN의 구조

CNN의 기본적인 구조는 다음과 같습니다.
<!--
![]({{site.url}}/assets/images/DL/CV/CNN-architecture.jpeg)

- INPUT : `28 x 28 x 1`
- Conv_1 : Convolution Layer : `5 x 5 x 1` filter `n1`개 사용
  - output shape `24 x 24 x n1`
- Max-Pooling : Pooling Layer : `2 x 2` max pooling 사용
  - output shape `12 x 12 x n1`
- Conv_2 : Convolution Layer : `5 x 5 x 1` filter `n2`개 사용
  - output shape `8 x 8 x n2`
- Max-Pooling : Pooling Layer : `2 x 2` max pooling 사용
  - output shape `4 x 4 x n2`
- fc_3 : Fully-Connected Layer : 
  - output shape
- fc_4 : Fully-Connected Layer : 
  - output shape
- OUTPUT : `1 x 1 x 10`
-->

![]({{site.url}}/assets/images/DL/CV/CNN-example.png)

- INPUT : `120 x 160 x 1`
- Convolution 1 : Convolution Layer : `5 x 5 x 1` filter `12`개 사용
  - output shape `116 x 156 x 12`
- Maxpooling 1 : Pooling Layer : `2 x 2` max pooling 사용
  - output shape `58 x 78 x 12`
- Convolution 2  : Convolution Layer : `5 x 5 x 1` filter `16`개 사용
  - output shape `54 x 74 x 16`
- Maxpooling 2 : Pooling Layer : `2 x 2` max pooling 사용
  - output shape `27 x 37 x 16`
- Convolution 3 : Convolution Layer : `4 x 4 x 1` filter `20`개 사용
  - output shape `24 x 34 x 20`
- Maxpooling 3 : Pooling Layer : `2 x 2` max pooling 사용
  - output shape `12 x 17 x 20`
- FC 1 : Fully-Connected Layer
  - output shape : `512 x 1`
- FC 2 : Fully-Connected Layer
  - output shape : `128 x 1`
- FC 3 : Fully-Connected Layer
  - output shape : `4 x 1`
- OUTPUT : `4 x 1`

## 1. Convolution Layer

### Convolution ; 합성곱

Convolution은 이미지로부터 feature를 추출하기 위해 사용하는 연산입니다. 이를 그림으로 나타내면 다음과 같습니다.

![Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature]({{site.url}}/assets/images/DL/CV/CNN-convolution.gif)

- 초록색 부분 : 입력 이미지 `5 x 5 x 1`
- 노란색 부분 : filter = kernel `3 x 3 x 1`
- 빨간색 숫자 : filter의 값 : 가중치(weight)
- 빨간색 부분 : feature map

위 그림에서는 `5 x 5` 입력 이미지에 대하여 `3 x 3` filter를 1개 사용하여 한칸씩 움직이며(`stride = 1`) 매번 이미지의 일부와 filter 간 matrix operation을 수행하여 최종적으로 `3 x 3` feature map을 추출합니다. 이때 matrix operation, 즉 각 요소끼리 곱하고 이를 모두 더하는 연산을 convolution이라고 합니다.

### 2차원 데이터에서의 Convolution

흑백 이미지는 명암만을 표현하여 1개의 채널을 갖는 2차원 데이터입니다.

예를 들어, `4 x 4 x 1` 입력 이미지에 대하여 `3 x 3 x 1` filter를 1개 사용하여 convolution을 수행한다고 생각해봅시다. 입력 이미지와 filter 간 matrix operation을 수행하여 `2 x 2 x 1` feature map, 즉 1개의 채널을 갖는 feature map을 반환합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-2d-convolution.png)

### 3차원 데이터서의 Convolution

컬러 이미지는 Red, Green, Blue 총 3개의 채널을 갖는 3차원 데이터입니다. 3차원 데이터에 대하여 convolution을 수행할 때에는 입력 데이터의 채널 수와 filter의 채널 수가 같아야 합니다.

예를 들어, `4 x 4 x 3` 입력 이미지에 대하여 `3 x 3 x 3` filter를 1개 사용하여 convolution을 수행한다고 가정해봅시다. 각각의 채널 별로 입력 이미지와 filter 간 matirx operation을 수행한 뒤 이들을 모두 더하여 `2 x 2 x 1` feature map, 즉 1개의 채널을 갖는 feature map을 반환합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-3d-convolution.png)

일반적으로 CNN에서는 `W x H x C` 입력 이미지에 대하여 `FW x FH x FC` filter를 `FN`개 사용하여 convolution을 수행함으로써 `OW x OH x FN` feature map을 반환하도록 합니다.

![]({{site.url}}/assets/images/DL/CV/CNN-3d-convolution-generalization.png)

### Filter = Kernel

Filter(=Kernel)은 convolution을 수행할 때 사용되는 정사각행렬입니다. CNN에서 filter는 학습 대상 파라미터입니다. 즉 filter 내 숫자들은 가중치(weight)로, backpropagation을 통해 학습됩니다.

- **filter의 크기 (filter size = kernel size)**
  - 일반적으로 이미지의 크기가 클수록 더 큰 filter를 사용합니다.
  - 보통 큰 size의 filter를 한 개 사용하는 것보다 작은 size의 filter를 여러 개 사용하는 것이 성능이 더 좋다고 더 좋은 성능을 낸다고 알려져 있습니다.
- **filter의 개수**
  - 하나의 입력에 여러 개의 filter를 사용하면 다양한 feature들을 추출할 수 있습니다.
  - 일반적으로 각 레이어 별 연산 시간 및 양이 일정할 수 있도록 filter의 개수를 결정합니다.
  - 예를 들어, 이전 레이어에서 픽셀 수가 1/4로 줄어들었다면, 다음 레이어에서는 filter 수를 4배 늘리는 방식입니다.
  - 입력 이미지로부터 가까운 레이어에서는 filter를 적게 사용하고, 입력 이미지로부터 먼 레이어에서는 filter를 많이 사용하는 경향이 있습니다.
- **stride** : stride는 filter를 몇 칸씩 움직이면서 convolution을 수행할 것인지를 의미합니다.
  - 일반적으로 `stride = 1`로 설정합니다.
  - stride 값이 커지면 local feature의 특성을 고려하지 못한 global feature를 추출하게 될 가능성이 높습니다.

### Padding

Padding은 입력 이미지의 가장자리에 특정 값으로 설정된 픽셀들을 추가하는 것을 의미합니다. 일반적으로 0으로 설정된 픽셀들을 추가하는 zero-padding을 많이 사용합니다.

**padding의 효과**는 다음과 같습니다.

- convolution 이후 feature map의 크기가 입력 이미지의 크기에 비해 작아지는 것을 방지할 수 있습니다.
- padding을 적용함으로써 이미지의 가장자리에 있는 정보의 손실을 줄일 수 있습니다.

예를 들어, `4 x 4 x 1` 이미지가 있다고 가정해봅시다.

![]({{site.url}}/assets/images/DL/CV/CNN-padding.png)

왼쪽 그림처럼 입력 이미지에 padding을 적용하지 않고 `3 x 3 x 1` filter를 `stride = 1`로 하여 convolution을 수행하면 `2 x 2 x 1` feature map을 얻게 됩니다. 한편 오른쪽 그림처럼 이 입력 이미지에 `zero-padding = 1`을 적용하여 `3 x 3 x 1` filter를 `stride = 1`로 하여 convolution을 수행하면 입력 이미지와 크기가 동일한 `4 x 4 x 1` feature map을 얻을 수 있습니다.

### Feature Map & Activation Map

feature map은 convolution을 수행하여 반환되는 출력 결과를 의미합니다. feature map의 크기는 입력 데이터에 대한 filter의 크기, stride, padding size 등에 의해 결정됩니다. 공식은 다음과 같습니다.

$O = \frac{I - F + 2P}{S} + 1$

- $O$ : output size = output width/height
- $I$ : input size = input width/height
- $F$ : filter size = filter width/height
- $P$ : padding size
- $S$ : stride

activation map은 feature map에 ReLU와 같은 활성화 함수(activation function)을 적용한 것을 말합니다. 따라서 convolution layer의 최종적인 출력이 activation map이라고 할 수 있습니다.

## 2. Pooling layer

### Pooling

pooling은 sub sampling입니다. 즉 데이터의 크기를 줄이는 것입니다. 아래의 그림은 `5 x 5` 데이터에 `3 x 3` pooling을 적용하는 것을 보여줍니다.

![3x3 pooling over 5x5 convolved feature]({{site.url}}/assets/images/DL/CV/CNN-pooling.png)

**pooling의 효과**는 다음과 같습니다.

- overfitting을 방지합니다.
- 데이터의 크기를 줄여 파라미터 수가 줄어듦에 따라 computation 또한 줄어듭니다.

**pooling의 종류**는 다음과 같습니다.

![Types of Pooling]({{site.url}}/assets/images/DL/CV/CNN-pooling-types.png)

- Max Pooling : 영역 내 최대값 반환
- Average Pooling : 영역 내 평균값 반환
- Min Pooling : 영역 내 최소값 반환
- Stochastic Pooling
- Cross Channel Pooling
- ...

### Pooling Layer in CNN

pooling layer는 convolution layer의 출력을 입력으로 받아 크기를 줄이거나 특정 데이터를 강조하기 위해 사용됩니다. 일반적으로 pooling 크기와 stride를 동일하게 설정하여 모든 픽셀이 한번씩 처리될 수 있도록 합니다. 또 CNN에서는 주로 max pooling을 사용하는데, 이를 통해 차원을 축소할 수 있고 지배적인 feature를 추출할 수 있습니다.

**pooling layer의 특징**은 다음과 같습니다.

- 학습 대상 파라미터가 없습니다.
- pooling layer의 입력과 출력의 채널 수는 동일합니다. 즉 pooling이 채널 수에 영향을 미치지 않아 채널 수가 유지됩니다. (independent)
- pooling layer의 입력인 feature map에 변화가 있더라도 pooling의 출력에는 변화가 거의 없습니다. (robustness)

**pooling Layer의 output size**는 다음과 같습니다.

$O = \frac{I}{P}$

- $O$ : output size = output width/height
- $I$ : input size = input width/height
- $P$ : padding size

## 3. Fully-Connected layer

Fully-Connected layer에서는 데이터를 flatten하여 1차원 배열로 변환하고, 

![]({{site.url}}/assets/images/DL/CV/CNN-fully-connected-layer.png)

Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer. The Fully-Connected layer is learning a possibly non-linear function in that space.
Now that we have converted our input image into a suitable form for our Multi-Level Perceptron, we shall flatten the image into a column vector. The flattened output is fed to a feed-forward neural network and backpropagation applied to every iteration of training. Over a series of epochs, the model is able to distinguish between dominating and certain low-level features in images and classify them using the Softmax Classification technique.

Full-Connected layer를 추가하는 것은 convolution layer의 출력으로 표현되는 high-level feature들의 비선형 조합을 배우는 저렴한 방법입니다. 완전 연결 계층은 해당 공간에서 가능한 비선형 함수를 학습합니다.
이제 입력 이미지를 Multi-Level Perceptron에 적합한 형식으로 변환 했으므로 이미지를 열 벡터로 병합합니다. 평탄화 된 출력은 피드 포워드 신경망에 공급되고 모든 훈련 반복에 적용되는 역 전파입니다. 일련의 시대에 걸쳐 모델은 이미지의 지배적 특징과 특정 저수준 특징을 구별하고 Softmax 분류 기술을 사용하여 분류 할 수 있습니다.

## CNN의 variants

다양한 CNN 계열 

There are various architectures of CNNs available which have been key in building algorithms which power and shall power AI as a whole in the foreseeable future. Some of them have been listed below:

- LeNet
- AlexNet
- VGGNet
- GoogLeNet
- ResNet
- ZFNet

## 참고자료

[Backpropagation applied to handwritten zip code recognition](https://ieeexplore.ieee.org/document/6795724)  
[A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)  
[TAEWAN.KIM님의 블로그](http://taewan.kim/post/cnn/)
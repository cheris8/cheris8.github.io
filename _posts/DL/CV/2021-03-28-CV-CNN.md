---
title: '[딥러닝] CNN (Convolution Neural Networks) ; 합성곱 신경망'

categories:
  - Deep Learning
tags:
  - Deep Learning

last_modified_at: 2021-03-28T08:06:00-05:00

classes: wide
use_math: true
---

이 글은 CNN의 개념, 구조, 순전파, 역전파에 관한 기록입니다.

## CNN 개념

CNN은 이미지를 다루는 데에 활용되는 Deep Neural Network입니다.

예를 들어, 아래와 같이 `4x4x3` RGB 이미지가 있다고 가정해봅시다.

![4x4x3 RGB image]({{site.url}}/assets/images/DL/CV/CNN-input-image.png)

CNN의 목표는 예측에 도움이 되는 특징(feature)의 손실 없이 이미지를 줄이는 것입니다. 이를 위해 CNN에서는 Convolution layer와 Relu layer, Pooling layer를 통해 feature를 학습하고, Fully connected layer를 통해 이미지를 분류합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-overview.jpeg)

즉 CNN은 크게 Convolution layer, Pooling layer, Full-connected layer 세가지 layer로 구성됩니다.

> `[((CONV => RELU) * m => POOL) * n => (FC => RELU) * k ]`
> m=1~5, n=큰 수, k=0~2

- Convolution Layer
  - Filter 개수
  - Filter 크기
  - Stride
- Pooling Layer
- Fully-Connected Layer

The objective of the Convolution Operation is to extract the high-level features such as edges, from the input image. ConvNets need not be limited to only one Convolutional Layer. Conventionally, the first ConvLayer is responsible for capturing the Low-Level features such as edges, color, gradient orientation, etc. With added layers, the architecture adapts to the High-Level features as well, giving us a network which has the wholesome understanding of images in the dataset, similar to how we would.

## CNN의 아키텍처

CNN의 기본적인 구조는 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-architecture.jpeg)

- input : `28 x 28 x 1`
- Conv_1 : Convolution Layer : `5 x 5 x 1` filter `n1`개 사용 => output shape `24 x 24 x n1`
- Max-Pooling : Pooling Layer : `2 x 2` max pooling 사용 => output shape `12 x 12 x n1`
- Conv_2 : Convolution Layer : `5 x 5 x 1` filter `n2`개 사용 => output shape `8 x 8 x n2`
- Max-Pooling : Pooling Layer : `2 x 2` max pooling 사용 => output shape `4 x 4 x n2`
- fc_3 : Fully-Connected Layer : 
- fc_4 : Fully-Connected Layer : 
- output : `1 x 1 x 10`

CIFAR-10 데이터를 다루기 위한 간단한 ConvNet은 `INPUT-CONV-RELU-POOL-FC` 로 구축할 수 있다.

- INPUT : 입력 이미지가 가로32, 세로32, 그리고 RGB 채널을 가지는 경우 입력의 크기는 `32 x 32 x 3`
- CONV 레이어 : 입력 이미지의 일부 영역과 연결되어 있으며, 이 연결된 영역과 자신의 가중치의 내적 연산 (dot product) 을 계산하게 된다. 결과 볼륨은 `32x32x12`와 같은 크기를 갖게 된다.
- RELU 레이어 : max(0,x)와 같이 각 요소에 적용되는 액티베이션 함수 (activation function)이다. 이 레이어는 볼륨의 크기를 변화시키지 않는다 `32x32x12`
- POOL 레이어 : (가로,세로) 차원에 대해 다운샘플링 (downsampling)을 수행해 `16x16x12`와 같이 줄어든 볼륨을 출력한다.
- FC (fully-connected) 레이어 : 클래스 점수들을 계산해 `1x1x10`의 크기를 갖는 볼륨을 출력한다. 10개 숫자들은 10개 카테고리에 대한 클래스 점수에 해당한다. 레이어의 이름에서 유추 가능하듯, 이 레이어는 이전 볼륨의 모든 요소와 연결되어 있다.

- Convolution ; 합성곱
- Channel ; 채널
- Filter ; 필터 = Kernel 커널
- Strid ; 스트라이드
- Padding ; 패딩
- Feature Map ; 피쳐맵
- Activation Map
- Pooling

## 1. Convolution Layer

### Convolution ; 합성곱

Convolution은 이미지로부터 feature를 추출하기 위해 사용하는 연산입니다. 이를 그림으로 나타내면 다음과 같습니다.

![Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature]({{site.url}}/assets/images/DL/CV/CNN-convolution.gif)

- 초록색 부분 : 입력 이미지 `5 x 5 x 1`
- 노란색 부분 : filter = kernel `3 x 3 x 1`
- 빨간색 숫자 : filter의 값 : 가중치(weight)
- 빨간색 부분 : feature map

위 그림에서는 `5 x 5` 입력 이미지에 대하여 `3 x 3` filter를 1개 사용하여 한칸씩 움직이며(`stride = 1`) 매번 이미지의 일부와 filter 간 matrix operation을 수행하여 최종적으로 `3 x 3` feature map을 추출합니다. 이때 matrix operation, 즉 각 요소끼리 곱하고 이를 모두 더하는 연산을 convolution이라고 합니다.

### 2차원 데이터에서의 Convolution

흑백 이미지는 명암만을 표현하여 1개의 채널을 갖는 2차원 데이터입니다.

예를 들어, `4 x 4 x 1` 입력 이미지에 대하여 `3 x 3 x 1` filter를 1개 사용하여 convolution을 수행한다고 생각해봅시다. 입력 이미지와 filter 간 matrix operation을 수행하여 `2 x 2 x 1` feature map, 즉 1개의 채널을 갖는 feature map을 반환합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-2d-convolution.png)

### 3차원 데이터서의 Convolution

컬러 이미지는 Red, Green, Blue 총 3개의 채널을 갖는 3차원 데이터입니다. 3차원 데이터에 대하여 convolution을 수행할 때에는 입력 데이터의 채널 수와 filter의 채널 수가 같아야 합니다.

예를 들어, `4 x 4 x 3` 입력 이미지에 대하여 `3 x 3 x 3` filter를 1개 사용하여 convolution을 수행한다고 가정해봅시다. 각각의 채널 별로 입력 이미지와 filter 간 matirx operation을 수행한 뒤 이들을 모두 더하여 `2 x 2 x 1` feature map, 즉 1개의 채널을 갖는 feature map을 반환합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/DL/CV/CNN-3d-convolution.png)

일반적으로 CNN에서는 `W x H x C` 입력 이미지에 대하여 `FW x FH x FC` filter를 `FN`개 사용하여 convolution을 수행함으로써 `OW x OH x FN` feature map을 반환하도록 합니다.

![]({{site.url}}/assets/images/DL/CV/CNN-3d-convolution-generalization.png)

### Filter = Kernel

convolution을 수행할 때 사용되는 filter는 CNN에서 학습 대상 파라미터입니다. 다시 말해, filter 내 숫자들은 가중치(weight)로, backpropagation을 통해 학습됩니다.

- **filter의 크기 (filter size = kernel size)**
  - 일반적으로 이미지의 크기가 클수록 더 큰 filter를 사용합니다.
  - 보통 큰 size의 filter를 한 개 사용하는 것보다 작은 size의 filter를 여러 개 사용하는 것이 성능이 더 좋다고 더 좋은 성능을 낸다고 알려져 있습니다.
- **filter의 개수**
  - 하나의 입력에 여러 개의 filter를 사용하면 다양한 feature들을 추출할 수 있습니다.
  - 일반적으로 각 레이어 별 연산 시간 및 양이 일정할 수 있도록 filter의 개수를 결정합니다.
  - 예를 들어, 이전 레이어에서 픽셀 수가 1/4로 줄어들었다면, 다음 레이어에서는 filter 수를 4배 늘리는 방식입니다.
  - 입력 이미지로부터 가까운 레이어에서는 filter를 적게 사용하고, 입력 이미지로부터 먼 레이어에서는 filter를 많이 사용하는 경향이 있습니다.
- **stride** : stride는 filter를 몇 칸씩 움직이면서 convolution을 수행할 것인지를 의미합니다.
  - 일반적으로 `stride = 1`로 설정합니다.
  - stride 값이 커지면 local feature의 특성을 고려하지 못한 global feature를 추출하게 될 가능성이 높습니다.

### Padding ; 패딩

padding은 입력 이미지의 가장자리에 특정 값으로 설정된 픽셀들을 추가하는 것을 의미합니다. 일반적으로 0으로 설정된 픽셀들을 추가하는 zero-padding을 많이 사용합니다.

padding을 사용하는 이유는 크게 두가지 입니다. 먼저, convolution 이후 feature map의 크기가 입력 이미지의 크기보다 작아지는 것을 방지하기 위함입니다. 다음으로, padding을 적용함으로써 이미지의 가장자리에 있는 정보 손실을 줄일 수 있습니다.

예를 들어, `4 x 4 x 1` 이미지가 있다고 가정해봅시다.

![]({{site.url}}/assets/images/DL/CV/CNN-padding.png)

왼쪽 그림처럼 입력 이미지에 padding을 적용하지 않고 `3 x 3 x 1` filter를 `stride = 1`로 하여 convolution을 수행하면 `2 x 2 x 1` feature map을 얻게 됩니다. 한편 오른쪽 그림처럼 이 입력 이미지에 `zero-padding = 1`을 적용하여 `3 x 3 x 1` filter를 `stride = 1`로 하여 convolution을 수행하면 입력 이미지와 크기가 동일한 `4 x 4 x 1` feature map을 얻을 수 있습니다.

### Feature Map & Activation Map

feature map은 convolution을 수행하여 반환되는 출력 결과를 의미합니다. feature map의 크기는 입력 데이터에 대한 filter의 크기, stride, padding size 등에 의해 결정됩니다. 공식은 다음과 같습니다.

$O = \frac{I - F + 2P}{S} + 1$

- $O$ : output size = output width/height
- $I$ : input size = input width/height
- $F$ : filter size = filter width/height
- $P$ : padding size
- $S$ : stride

Activation Map은 feature map에 활성화 함수(activation function)을 적용한 결과입니다. 따라서 Convolution layer의 최종 출력 결과가 activation map이라고 할 수 있습니다.

## 2. Pooling layer

Pooling Layer는 Convolution Layer의 출력을 입력으로 받아 크기를 줄이거나 특정 데이터를 강조하는 용도로 사용됩니다.

![3x3 pooling over 5x5 convolved feature]({{site.url}}/assets/images/DL/CV/CNN-pooling.gif)

이를 통해 차원을 축소할 수 있고, 지배적인 feature를 추출할 수 있습니다.

![Types of Pooling]({{site.url}}/assets/images/DL/CV/CNN-pooling-types.png)

Pooling의 종류에는 크게 Max Pooling, Average Pooling, Min Pooling이 존재합니다. CNN에서는 일반적으로 Max Pooling을 사용합니다.

- Max Pooling : 영역 내 최대값 반환
- Average Pooling : 영역 내 평균값 반환
- Min Pooling : 영역 내 최소값 반환

Pooling Layer의 output size는 다음과 같습니다.

$O = \frac{I}{P}$

- $O$ : output size = output width/height
- $I$ : input size = input width/height
- $P$ : padding size

일반적으로 pooling 크기와 stride를 같은 크기로 설정하여 모든 픽셀이 한번씩 처리될 수 있도록 합니다.

## Convolution layer vs. Pooling layer

| |Convolution Layer | Pooling Lyaer |
|-|------------------|---------------|
|학습 대상 파라미터|있음| 없음|
|행렬 크기       | |감소|
|채널 수        |    |채널 수 변경 없음|

## 3. Fully-Connected layer

Fully-Connected layer에서는 이전까지의 layer의 출력을 입력으로 받아 flatten하여 1차원 배열로 변환합니다. 그리고 

![]({{site.url}}/assets/images/DL/CV/CNN-fully-connected-layer.png)

Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer. The Fully-Connected layer is learning a possibly non-linear function in that space.
Now that we have converted our input image into a suitable form for our Multi-Level Perceptron, we shall flatten the image into a column vector. The flattened output is fed to a feed-forward neural network and backpropagation applied to every iteration of training. Over a series of epochs, the model is able to distinguish between dominating and certain low-level features in images and classify them using the Softmax Classification technique.

Full-Connected layer를 추가하는 것은 convolution layer의 출력으로 표현되는 high-level feature들의 비선형 조합을 배우는 저렴한 방법입니다. 완전 연결 계층은 해당 공간에서 가능한 비선형 함수를 학습합니다.
이제 입력 이미지를 Multi-Level Perceptron에 적합한 형식으로 변환 했으므로 이미지를 열 벡터로 병합합니다. 평탄화 된 출력은 피드 포워드 신경망에 공급되고 모든 훈련 반복에 적용되는 역 전파입니다. 일련의 시대에 걸쳐 모델은 이미지의 지배적 특징과 특정 저수준 특징을 구별하고 Softmax 분류 기술을 사용하여 분류 할 수 있습니다.

## 다양한 CNN 계열 아키텍처

There are various architectures of CNNs available which have been key in building algorithms which power and shall power AI as a whole in the foreseeable future. Some of them have been listed below:

- LeNet
- AlexNet
- VGGNet
- GoogLeNet
- ResNet
- ZFNet

## 참고자료

[Backpropagation applied to handwritten zip code recognition](https://ieeexplore.ieee.org/document/6795724)  
[A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)  
[TAEWAN.KIM님의 블로그](http://taewan.kim/post/cnn/)
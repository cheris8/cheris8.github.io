---
title: '[딥러닝] CNN (Convolution Neural Networks) ; 합성곱 신경망'

categories:
  - Deep Learning
tags:
  - Deep Learning

last_modified_at: 2021-03-28T08:06:00-05:00

classes: wide
use_math: true
---

이 글은 CNN의 개념, 구조, 순전파, 역전파에 관한 기록입니다.

## CNN 개념

CNN은 이미지를 다루는 데에 활용되는 Deep Neural Network입니다.

예를 들어, 아래와 같이 `4x4x3` RGB 이미지가 있다고 가정해봅시다.

![4x4x3 RGB image]({{site.url}}/assets/images/CNN-input-image.jpeg)

CNN의 목표는 예측에 도움이 되는 특징(feature)의 손실 없이 이미지를 줄이는 것입니다. 이를 위해 CNN에서는 Convolution layer와 Relu layer, Pooling layer를 통해 feature를 학습하고, Fully connected layer를 통해 이미지를 분류합니다. 이를 그림으로 나타내면 다음과 같습니다.

![]({{site.url}}/assets/images/CNN-overview.jpeg)

즉 CNN은 크게 Convolution layer, Pooling layer, Full-connected layer 세가지 layer로 구성됩니다.

> `[((CONV => RELU) * m => POOL) * n => (FC => RELU) * k ] m=1~5, n=큰 수, k=0~2`

- Convolution Layer
  - Filter 개수
  - Filter 크기
  - Stride
- Pooling Layer
- Fully-Connected Layer

## CNN의 아키텍처

CIFAR-10 데이터를 다루기 위한 간단한 ConvNet은 `INPUT-CONV-RELU-POOL-FC` 로 구축할 수 있다.

- INPUT : 입력 이미지가 가로32, 세로32, 그리고 RGB 채널을 가지는 경우 입력의 크기는 `32 x 32 x 3`
- CONV 레이어 : 입력 이미지의 일부 영역과 연결되어 있으며, 이 연결된 영역과 자신의 가중치의 내적 연산 (dot product) 을 계산하게 된다. 결과 볼륨은 `32x32x12`와 같은 크기를 갖게 된다.
- RELU 레이어 : max(0,x)와 같이 각 요소에 적용되는 액티베이션 함수 (activation function)이다. 이 레이어는 볼륨의 크기를 변화시키지 않는다 `32x32x12`
- POOL 레이어 : (가로,세로) 차원에 대해 다운샘플링 (downsampling)을 수행해 `16x16x12`와 같이 줄어든 볼륨을 출력한다.
- FC (fully-connected) 레이어 : 클래스 점수들을 계산해 `1x1x10`의 크기를 갖는 볼륨을 출력한다. 10개 숫자들은 10개 카테고리에 대한 클래스 점수에 해당한다. 레이어의 이름에서 유추 가능하듯, 이 레이어는 이전 볼륨의 모든 요소와 연결되어 있다.

- Convolution ; 합성곱
- Channel ; 채널
- Filter ; 필터 = Kernel 커널
- Strid ; 스트라이드
- Padding ; 패딩
- Feature Map ; 피쳐맵
- Activation Map
- Pooling

## Input
### 1.2 채널, Channel

이미지 픽셀 하나하나는 실수입니다. 컬러 사진은 천연색을 표현하기 위해서, 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터입니다.

컬러 이미지는 3개의 채널로 구성됩니다. 
반면에 흑백 명암만을 표현하는 흑백 사진은 2차원 데이터로 1개 채널로 구성됩니다. 
- 높이 = 39 픽셀, 폭 = 31 픽셀, 컬러 사진 데이터의 shape : `(39, 31, 3)`
- 높이 = 39 픽셀, 폭 = 31 픽셀, 흑백 사진 데이터의 shape : `(39, 31, 1)`

Convolution Layer에 유입되는 입력 데이터에는 한 개 이상의 필터가 적용됩니다. 1개 필터는 Feature Map의 채널이 됩니다. Convolution Layer에 n개의 필터가 적용된다면 출력 데이터는 n개의 채널을 갖게 됩니다.



## Convolution ; 합성곱

Convolution은 이미지로부터 feature를 추출하기 위해 사용하는 연산입니다. 이를 그림으로 나타내면 다음과 같습니다.

![Convoluting a 5x5x1 image with a 3x3x1 kernel to get a 3x3x1 convolved feature]({{site.url}}/assets/images/CNN-overview.jpeg)

- 초록색 부분 : `5x5x1` input image 입력 이미지
- 노란색 부분 : `3x3x1` filter = `3x3x1` kernerl
- 빨간색 숫자 : filter의 값 = weight parameter (학습 대상 파라미터)
- 빨간색 부분 : feature map

위 그림에서는 `5x5x1` input image에 대하여 `3x3` filter(filter size=3)를 1개 사용하여 한칸씩 움직이며(stride=1) 매번 이미지의 일부와 필터 간 matrix operation을 수행하여 최종적으로 `3x3` feature map을 추출합니다. 이때 matrix operation, 즉 각 요소끼리 곱하고 이를 모두 더하는 연산을 convolution이라고 합니다.

### filter = kernel

filter는 학습 대상 파라미터 입니다. 즉 CNN에서는 backpropagation을 통해 filter 내 값들을 학습합니다.

filter는 아래의 그림과 같이 왼쪽 상단에서 오른쪽 하단으로 이동합니다.

![Movement of the Kernel]({{site.url}}/assets/images/CNN-overview.jpeg)


또한, 위에서 확인해 본 것처럼 하나의 이미지에도 다양한 Filter를 사용하면 다양한 특징들이 추출된다. 

### Filter의 개수

Filter의 개수를 정하는 데에 왕도는 없습니다. 다만 일반적으로는 입력 이미지 근처에서는 적게 사용하고, 멀어질수록 더 많이 사용하는 경향이 있다.

Filter의 개수를 결정하는 일반적인 방법은 각 Layer에서 연산 시간/양을 일정하게 유지하여 시스템의 균형을 맞추는 방향으로 결정된다. 즉, 각 Layer에서 Feature map (Feature map은 보통 이미지를 Filter로 Convolution한 결과를 의미함)의 개수와 Pixel 수의 곱을 일정하게 유지할 수 있게 Filter 개수를 결정하면 된다.

예를 들면, Convolution layer에서 2x2 Subsampling을 하는 경우 Pixel 수가 1/4로 줄어들기 때문에 그 다음 Convolution 할 때는 Filter 수를 4배로 증가시켜 Feature map 수를 4배로 증가시키면 된다.

### filter size

보통 이미지의 크기가 클수록 더 큰 filter를 사용합니다.

일반적으로 큰 size의 filter를 한 개 사용하는 것과 작은 size의 filter를 여러 개 사용하는 것 중 후자가 더 좋은 성능을 보인다고 알려져 있습니다.

### stride

stride는 filter를 움직이는 칸 수를 의미합니다.

Stride는 Convolution 시 건너 뛸 픽셀 수를 의미한다. 

아래의 이미지는 Stride가 1인 경우다.

Stride 값이 커지면 중복되는 부분이 줄어들고 Convolution이 시도되는 범위가 줄어, Local feature의 특성을 다 고려하지 못한 Global feature가 만들어질 수도 있다.

### 1.3 필터(Filter) & Stride

필터는 이미지의 특징을 찾아내기 위한 공용 파라미터입니다. Filter를 Kernel이라고 하기도 합니다. CNN에서 Filter와 Kernel은 같은 의미입니다. 필터는 일반적으로 (4, 4)이나 (3, 3)과 같은 정사각 행렬로 정의됩니다. CNN에서 학습의 대상은 필터 파라미터 입니다. <그림 1>과 같이 입력 데이터를 지정된 간격으로 순회하며 채널별로 합성곱을 하고 모든 채널(컬러의 경우 3개)의 합성곱의 합을 Feature Map로 만듭니다. 필터는 지정된 간격으로 이동하면서 전체 입력데이터와 합성곱하여 Feature Map을 만듭니다. <그림 3>은 채널이 1개인 입력 데이터를 (3, 3) 크기의 필터로 합성곱하는 과정을 설명합니다.

필터는 입력 데이터를 지정한 간격으로 순회하면서 합성곱을 계산합니다. 여기서 지정된 간격으로 필터를 순회하는 간격을 Stride라고 합니다. <그림 4>는 strid가 1로 필터를 입력 데이터에 순회하는 예제입니다. strid가 2로 설정되면 필터는 2칸씩 이동하면서 합성곱을 계산합니다.

입력 데이터가 여러 채널을 갖을 경우 필터는 각 채널을 순회하며 합성곱을 계산한 후, 채널별 피처 맵을 만듭니다. 그리고 각 채널의 피처 맵을 합산하여 최종 피처 맵으로 반환합니다. 입력 데이터는 채널 수와 상관없이 필터 별로 1개의 피처 맵이 만들어 집니다.

![Convolution operation on a MxNx3 image matrix with a 3x3x3 Kernel]({{site.url}}/assets/images/CNN-overview.jpeg)

In the case of images with multiple channels (e.g. RGB), the Kernel has the same depth as that of the input image. Matrix Multiplication is performed between Kn and In stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed with the bias to give us a squashed one-depth channel Convoluted Feature Output.//
여러 채널이있는 이미지 (예 : RGB)의 경우 커널은 입력 이미지와 동일한 깊이를 갖습니다. 매트릭스 곱셈은 Kn과 In 스택 ([K1, I1]; [K2, I2]; [K3, I3]) 사이에서 수행되며 모든 결과는 편향과 합산되어 스쿼시 된 1 심도 채널 Convoluted Feature Output을 제공합니다.//

하나의 Convolution Layer에 크기가 같은 여러 개의 필터를 적용할 수 있습니다. 이 경우에 Feature Map에는 필터 갯수 만큼의 채널이 만들어집니다. 입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature Map의 채널이 됩니다.

Convolution Layer의 입력 데이터를 필터가 순회하며 합성곱을 통해서 만든 출력을 Feature Map 또는 Activation Map이라고 합니다. Feature Map은 합성곱 계산으로 만들어진 행렬입니다. Activation Map은 Feature Map 행렬에 활성 함수를 적용한 결과입니다. 즉 Convolution 레이어의 최종 출력 결과가 Activation Map입니다.

### output size

입력 데이터에 대한 필터의 크기와 Stride 크기에 따라서 Feature Map 크기가 결정됩니다. 공식은 다음과 같습니다.

$$O = \frac{I - F + 2P}{S} + 1$$

- $O$ : output size = output widht/height
- $I$ : input size = input width/height
- $F$ : filter size
- $S$ : stride
- $P$ : padding size

### Padding ; 패딩

패딩은 입력 데이터의 외곽에 지정된 픽셀만큼 특정 값(일반적으로 0)으로 채워넣는 것을 의미합니다. 보통 패딩 값으로 0을 사용합니다.

Convolution 레이어에서 Filter와 Stride의 영향으로 Feature Map의 크기는 입력 이미지의 크기보다 작습니다. 이때 이러한 Convolution 레이어의 출력 데이터가 줄어드는 것을 방지하는 방법이 패딩입니다.

<그림 6>은 (32, 32, 3) 데이터를 외각에 2 pixel을 추가하여 (36, 36, 3) 행렬을 만드는 예제입니다. Padding을 통해서 Convolution 레이어의 출력 데이터의 사이즈를 조절하는 기능이 외에, 외각을 “0”값으로 둘러싸는 특징으로 부터 인공 신경망이 이미지의 외각을 인식하는 학습 효과도 있습니다.

패딩을 사용하는 이유는 크게 두가지 입니다.
먼저, convolution 이후 특성맵의 크기가 입력 이미지의 크기보다 작아지는 것을 방지하기 위함입니다.
다음으로, 패딩을 함으로써 경계에 있는 정보 손실을 줄일 수 있다는 점이 있습니다.


$P=\frac{K−1}{2}$

$O = \frac{(W − K + 2P)}{S} + 1$

- $O$ : output height/length
- $W$ : input height/length
- $K$ : filter size
- $P$ : padding size
- $S$ : stride size

## Pooling layer

Pooling Layer는 Convolution Layer의 출력을 입력으로 받아 크기를 줄이거나 특정 데이터를 강조하는 용도로 사용됩니다.

![3x3 pooling over 5x5 convolved feature]({{site.url}}/assets/images/CNN-pooling.gif)

이를 통해 차원을 축소할 수 있고, 지배적인 feature를 추출할 수 있습니다.

![Types of Pooling]({{site.url}}/assets/images/CNN-pooling-types.png)

Pooling의 종류에는 크게 Max Pooling, Average Pooling, Min Pooling이 존재합니다. CNN에서는 일반적으로 Max Pooling을 사용합니다.

- Max Pooling : 영역 내 최대값 반환
- Average Pooling : 영역 내 평균값 반환
- Min Pooling : 영역 내 최소값 반환

Pooling Layer의 output size는 다음과 같습니다.

$$O = \frac{I}{P}$$

- $O$ : output size
- $I$ : input size
- $P$ : padding size

일반적으로 Pooing 크기와 Stride를 같은 크기로 설정하여 모든 원소가 한 번씩 처리 되도록 설정합니다.

## Convolution layer vs. Pooling layer

| |Convolution Layer | Pooling Lyaer |
|-|------------------|---------------|
|학습 대상 파라미터|있음| 없음|
|행렬 크기       |   |행렬의 크기 감소|
|채널 수        |    |채널 수 변경 없음|

## Fully connected layer

## 다양한 CNN 계열 아키텍처

There are various architectures of CNNs available which have been key in building algorithms which power and shall power AI as a whole in the foreseeable future. Some of them have been listed below:

- LeNet
- AlexNet
- VGGNet
- GoogLeNet
- ResNet
- ZFNet

## 참고자료

[Backpropagation applied to handwritten zip code recognition](https://ieeexplore.ieee.org/document/6795724)  
[A Comprehensive Guide to Convolutional Neural Networks — the ELI5 way](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)  
[TAEWAN.KIM님의 블로그](http://taewan.kim/post/cnn/)
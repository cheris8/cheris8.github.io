---
title: '[정보검색] 제7장 정보검색 모형 - 제11절 검색 성능 평가 척도'

categories:
  - Informatoin Retrieval
tags:
  - Informatoin Retrieval

last_modified_at: 2020-06-20T08:06:00-05:00

classes: wide
use_math: true
---

이 글은 정영미 교수님의 [정보검색연구](https://www.aladin.co.kr/shop/wproduct.aspx?ItemId=17330455)를 바탕으로 연세대학교 문성빈 교수님의 수업을 공부한 기록입니다.

## 정보검색시스템의 평가

- 정보검색시스템의 평가는 검색 성능(retrieval performance)이 가장 중요한 평가 기준
- 검색 성능
	- 검색의 효율성 (efficiency) : 검색 속도 또는 응답 속도
	- 검색의 효과성 (effectiveness) : 검색 결과의 정확성

## 검색 성능 척도 종류

| |적합문헌|부적합문헌| |
|-|------|-------|-|
|검색된 문헌|a|b|a+b|
|검색되지 않은 문헌|c|d||
||a+c|b+d|a+b+c+d|

- 재현율
	- $\frac{a}{a+c}$
- 정확률
	- $\frac{a}{a+b}$
- 누락률 (Snobbery Ratio)
	- 검색되지 않은 적합문헌의 비율 = 1 - 재현율
	- $1 - \frac{a}{a+c}$
- 잡음률 (Noise Factor)
	- 검색된 부적합문헌의 비율 = 1 - 정확률
	- $1 - \frac{a}{a+b}$
- 부적합률 (Fallout Ratio)
	- 전체 부적합문헌 중 검색된 문헌의 비율 = 1 - 배제율
	- $\frac{b}{b+d}$
- 배제율 (Correct-rejection Ratio)
	- 전체 부적합문헌 중 검색되지 않은 문헌의 비율 = 1 - 부적합률
	- $\frac{d}{b+d}$
- 보편율
	- $\frac{a+c}{a+b+c+d}$

## 평균재현율 & 평균정확률
	
- 검색시스템의 성능 평가를 위해서는 충분한 수의 질의에 대해 검색을 수행한 후 각각의 검색 결과로부터 재현율과 정확률의 평균값을 구하는 것이 필요
- 평균값을 구하기 위한 두가지 접근방법
	- 매크로 평가 (Macro Evaluation)
	- 마이크로 평가 (Micro Evaluation)

### 매크로 평가 (Macro Evaluation)

- 질의의 수가 $n$개일 때 각 질의에 대한 재현율과 정확률을 각각 따로 계산한 다음 이들을 모두 더하여 $n$으로 나누어준 값을 평균재현율과 평균정확률로 사용
	- 평균재현율 = $\frac{1}{n} \sum_{i=1}^n \frac{검색된 \ 적합문헌의 \ 수}{적합문헌의 \ 수}$
	- 평균정확률 = $\frac{1}{n} \sum_{i=1}^n \frac{검색된 \ 적합문헌의 \ 수}{검색문헌의 \ 수}$
- 질의지향적 방법
	- 질의 단위로 평균을 내는 것이기 때문
	- 이용자가 시스템에 기대할 수 있는 검색 성능
	- 일반적으로 흔히 사용
	
### 마이크로 평가 (Micro Evaluation)

- 먼저 $n$개의 질의에 대한 적합문헌의 수, 검색문헌의 수, 검색된 적합문헌의 수 등을 다 더한 다음 합한 값이 각각 재현율과 정확률 공식의 분자와 분모가 되도록 하여 평균재현율과 평균정확률을 구하는 방법
	- 평균재현율 = $\frac{ \sum_{i=1}^n 검색된 \ 적합문헌의 \ 수 }{ \sum_{i=1}^n 적합문헌의 \ 수 }$
	- 평균정확률 = $\frac{ \sum_{i=1}^n 검색된 \ 적합문헌의 \ 수 }{ \sum_{i=1}^n 검색문헌의 \ 수 }$
- 문헌지향적 방법
	- 문헌 단위로 평균을 구하는 것이기 때문
	- 시스템 입장에서 본 검색 성능

> 예제) 매크로 평가에서의 평균재현율과 평균정확률, 마이크로 평가에서의 평균재현율과 평균정확률을 각각 구하시오.

|질의|적합문헌의 수|검색문헌의 수|검색된 적합문헌의 수|
|-|--|-|-|
|1|10|3|2|
|2|3|3|2|

_매크로 평가_  
평균재현율 = $\frac{1}{2} \times ( \frac{2}{10} + \frac{2}{3}) = 0.43$  
평균정확률 = $\frac{1}{2} \times ( \frac{2}{3} + \frac{2}{3}) = 0.67$

_마이크로 평가_  
평균재현율 = $\frac{2+2}{10+3}$  
평균정확율 = $\frac{2+2}{3+3}$

## F 척도 (F-measure)

- 재현율과 정확률은 보통 한 쌍이 함께 사용되어 검색 성능을 나타내므로 두 개 이상의 시스템의 성능을 비교할 경우 어느 시스템의 성능이 확실하게 더 나은지를 판단하기 어려울 수 O
- 재현율과 정확률을 복합적으로 반영하는 단일가 척도인 F 척도 사용
- F 척도는 E 척도에 기반
- $F = 1 - E$
- $E = 1 - \frac{1}{\alpha \times \frac{1}{P} + (1-\alpha) \times \frac{1}{R} } = 1 - \frac{(\beta^2+1) P R}{\beta^2 P + R}$
	- $R$ : 재현율
	- $P$ : 정확률
	- $\alpha, \beta$ : 이용자가 정확률과 재현율에 부여하는 상대적인 중요도를 나타내는 파라미터
		- $\beta = \frac{1}{2}$ : 재현율의 중요도가 정확률의 1/2배가 되는 경우
		- $\beta = 2$ : 재현율의 중요도가 정확률의 2배가 되는 경우
		- $\beta = 1$ : 재현율과 정확률에 동일한 중요도를 부여한 경우
- E 척도는 값이 작을수록 높은 성능
- F 척도는 값이 클수록 높은 성능 ($F = 1 - E$)
- 일반적으로 많이 사용되는 F 척도
	- 재현율과 정확률에 동일한 중요도를 부여한 경우 ($\beta = 1$)
	- $F = \frac{2 P R }{P + R}$

## 11-지점 평균정확률 (11-point Average Precision)

- 검색결과가 순위화되지 않는 시스템에서는 일반적으로 재현율과 정확률을 한 쌍으로 하여 검색 성능을 측정하지만
- 검색된 문헌이 적합성 점수에 따라 순위화되어 제공되는 시스템에서는 적합문헌을 상위에 출력할수록 검색 성능이 높게 평가
	- $0.1, 0.2, \cdots , 1.0$ 등 표준적인 재현율 수준에서의 정확률을 산출하여 성능 곡선을 그려 서로 비교
	- 각 수준에서의 정확률을 더한 다음 평균을 산출하여 비교
- 11-지점 평균정확률
	- 11개의 표준 재현율 수준에서의 정확률 값을 구해 평균을 낸 것
- (질의 Q에 대하여) 문헌 순위에 따른 재현율-정확률

|문헌순위|문헌번호|적합/부적합|재현율|정확률|
|------|-----|--------|-----|----|
|1|25|적합문헌|0.2|1.0|
|2|130|적합문헌|0.4|1.0|
|3|29|부적합문헌|0.4|0.67|
|4|14|적합문헌|0.6|0.75|
|5|372|부적합문헌|0.6|0.60|
|6|48|적합문헌|0.8|0.67|
|7|55|부적합문헌|0.8|0.57|
|8|43|부적합문헌|0.8|0.50|
|9|123|부적합문헌|0.8|0.44|
|10|8|부적합문헌|0.8|0.40|
|11|35|부적합문헌|0.8|0.36|
|12|117|부적합문헌|0.8|0.33|
|13|21|적합문헌|1.0|0.38|
|14|5|부적합문헌|1.0|0.36|

- 재현율 수준이 표준화되어 있지 X
- 한 개의 재현율 값이 여러 개의 정확률 값을 갖는 경우가 O
- 11개의 표준 재현율 수준에서 고유한 정확률 값을 갖도록 보간법을 사용
	- 재현율 수준 $i$에서의 정확률은 $i$나 $i$보다 큰 실제 재현율 수준에서 가장 큰 정확률 값으로 선택
- 평균정확률
	- 질의 $n$개에 대해 재현율 수준 $r$에서의 평균정확률 $P_{AVE}(r)$은 각 질의 i에 대한 정확률 $P_i(r)$을 모두 더한 다음 질의의 수 $n$으로 나누어 산출
	- $P_{AVE}(r) = \frac{\sum_{i=1}^n P_i(r)}{n}$
- 11-지점 평균정확률
	- 각 재현율 수준에서의 평균정확률 $P_{AVE}(r)$를 더해 11로 나누어 산출

## n-순위 정확률

- 검색 결과가 순위화되는 시스템에서는 가능한 한 적합문헌이 상위 수준에 오도록 순위화하는 능력이 중요
	- 적합문헌이 상위 수준에 검색되도록 하는 성능을 평가하고자 할 때에는 n개의 문헌이 검색된 다음 정확률을 산출
- n 순위에서의 정확률을 산출하는 것

## 적합문헌 평균정확률 (Mean Average Precision ; MAP)

- 적합문헌을 상위에 오도록 검색하는 능력을 평가하는 척도
- 각 적합문헌이 검색될 때마다 측정한 정확률의 평균
- 모든 적합문헌에 대한 정확률의 평균을 낸 것

## R-정확률 (R-Precision)

- 대규모 문헌집단을 대상으로 한 검색실험에서 적합문헌의 수가 매우 많을 때 유용한 검색 성능 척도
- R은 질의에 대해 적합한 문헌의 수로서 R-정확률은 R개의 문헌이 검색된 후 측정한 정확률
- 예시) 질의에 대한 적합문헌의 수가 20개일 경우 상위 20개의 문헌이 검색된 다음 정확률을 산출

## 정확률 히스토그램 (Precision Histogram)

- 적합문헌 평균정확률과 R-정확률
	- 검색 알고리즘의 비교를 위한 척도일 뿐만 아니라 
	- 질의 별 성능을 비교하기 위한 척도로 또한 적합
- 정확률 히스토그램
	- 질의 별 성능을 비교하는 방법
	- 각 질의 별로 산출한 평균정확률 혹은 R-정확률의 차이를 그래프로 나타내는 것
	- 비교 대상이 되는 알고리즘이 여러 개일 경우 평균 성능을 산출한 다음 각 알고리즘의 성능에서 평균 성능을 뺀 값으로 각 알고리즘의 성능을 평가할 수도 O

